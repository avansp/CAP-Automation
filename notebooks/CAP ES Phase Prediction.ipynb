{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cardiac MRI View Prediction\n",
    "\n",
    "The following notebook uses a trained neural network to predict the ES phase for 4-chamber and short-axis series in a directory of dicom files. Prior to running this script, ensure you have run \"CAP View Prediction\" so that the 4-chamber and short-axis series have been identified. Alternatively, you can run the analysis on a single series of images that you have previously identified as 4-chamber or short-axis views. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, import the necessary packages to run the analysis. The required libraries are pydicom, pandas, and tensorflow. The original analysis was run using python 3.6.8, pydicom 1.2.2, and tensorflow 2.4.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.6.8 |Anaconda, Inc.| (default, Feb 21 2019, 18:30:04) [MSC v.1916 64 bit (AMD64)]\n",
      "Pydicom: 1.2.2\n",
      "TensorFlow: 2.4.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pydicom \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "\n",
    "print('Python: {}'.format(sys.version))\n",
    "print('Pydicom: {}'.format(pydicom.__version__))\n",
    "print('TensorFlow: {}'.format(tf.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow can be run with or without GPU support. If GPU support through tensorflow is enabled and available, the following code will display and available GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemError",
     "evalue": "GPU device not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-ce08ddae0a7d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdevice_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgpu_device_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdevice_name\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'/device:GPU:0'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m   \u001b[1;32mraise\u001b[0m \u001b[0mSystemError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'GPU device not found'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Found GPU at: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mSystemError\u001b[0m: GPU device not found"
     ]
    }
   ],
   "source": [
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To disable the GPU, run the following code. DO NOT run this cell if you would prefer to use the available GPU (recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only use CPU for right now - Set CPU as only available physical device\n",
    "my_devices = tf.config.experimental.list_physical_devices(device_type='CPU')\n",
    "tf.config.experimental.set_visible_devices(devices= my_devices, device_type='CPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0 Single Patient\n",
    "#### Finding SA and 4CH View Series\n",
    "\n",
    "To start, we will load only the 4-chamber or short-axis views from a folder of dicom files. Importantly, this analysis expects view selection to have been run prior to this notebook. We will load in the series information from the .csv file that was created by the view selection analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient ID</th>\n",
       "      <th>Series ID</th>\n",
       "      <th>Series Number</th>\n",
       "      <th>Frames</th>\n",
       "      <th>Series Description</th>\n",
       "      <th>Predicted View</th>\n",
       "      <th>Confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CHD1055302</td>\n",
       "      <td>2.16.124.113543.6006.99.4489543484581785604</td>\n",
       "      <td>1501</td>\n",
       "      <td>90</td>\n",
       "      <td>flow_bh_ao_sense</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CHD1055302</td>\n",
       "      <td>2.16.124.113543.6006.99.4545974342301296934</td>\n",
       "      <td>1101</td>\n",
       "      <td>480</td>\n",
       "      <td>sa_sense</td>\n",
       "      <td>SA</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CHD1055302</td>\n",
       "      <td>2.16.124.113543.6006.99.4513285645466080530</td>\n",
       "      <td>1401</td>\n",
       "      <td>80</td>\n",
       "      <td>4ch_sense</td>\n",
       "      <td>4CH</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHD1055302</td>\n",
       "      <td>2.16.124.113543.6006.99.4544301574540994342</td>\n",
       "      <td>1201</td>\n",
       "      <td>60</td>\n",
       "      <td>lvot_sense</td>\n",
       "      <td>LVOT</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CHD1055302</td>\n",
       "      <td>2.16.124.113543.6006.99.4575318287899584458</td>\n",
       "      <td>701</td>\n",
       "      <td>120</td>\n",
       "      <td>4ch_sense</td>\n",
       "      <td>4CH</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CHD1055302</td>\n",
       "      <td>2.16.124.113543.6006.99.4557103526600474423</td>\n",
       "      <td>501</td>\n",
       "      <td>12</td>\n",
       "      <td>bb_-_ax_pa_clear</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CHD1055302</td>\n",
       "      <td>2.16.124.113543.6006.99.4492460316146916281</td>\n",
       "      <td>901</td>\n",
       "      <td>90</td>\n",
       "      <td>rt_2ch_sense</td>\n",
       "      <td>2CH RT</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CHD1055302</td>\n",
       "      <td>2.16.124.113543.6006.99.4569864505174670623</td>\n",
       "      <td>801</td>\n",
       "      <td>180</td>\n",
       "      <td>rvot_sense</td>\n",
       "      <td>RVOT</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CHD1055302</td>\n",
       "      <td>2.16.124.113543.6006.99.7493418895009265798</td>\n",
       "      <td>1801</td>\n",
       "      <td>30</td>\n",
       "      <td>lt_pa_sense</td>\n",
       "      <td>SA</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CHD1055302</td>\n",
       "      <td>2.16.124.113543.6006.99.4488755540510057828</td>\n",
       "      <td>601</td>\n",
       "      <td>30</td>\n",
       "      <td>lt_2ch_sense</td>\n",
       "      <td>2CH LT</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Patient ID                                    Series ID  Series Number  \\\n",
       "0  CHD1055302  2.16.124.113543.6006.99.4489543484581785604           1501   \n",
       "1  CHD1055302  2.16.124.113543.6006.99.4545974342301296934           1101   \n",
       "2  CHD1055302  2.16.124.113543.6006.99.4513285645466080530           1401   \n",
       "3  CHD1055302  2.16.124.113543.6006.99.4544301574540994342           1201   \n",
       "4  CHD1055302  2.16.124.113543.6006.99.4575318287899584458            701   \n",
       "5  CHD1055302  2.16.124.113543.6006.99.4557103526600474423            501   \n",
       "6  CHD1055302  2.16.124.113543.6006.99.4492460316146916281            901   \n",
       "7  CHD1055302  2.16.124.113543.6006.99.4569864505174670623            801   \n",
       "8  CHD1055302  2.16.124.113543.6006.99.7493418895009265798           1801   \n",
       "9  CHD1055302  2.16.124.113543.6006.99.4488755540510057828            601   \n",
       "\n",
       "   Frames Series Description Predicted View  Confidence  \n",
       "0      90   flow_bh_ao_sense          OTHER        1.00  \n",
       "1     480           sa_sense             SA        1.00  \n",
       "2      80          4ch_sense            4CH        1.00  \n",
       "3      60         lvot_sense           LVOT        1.00  \n",
       "4     120          4ch_sense            4CH        1.00  \n",
       "5      12   bb_-_ax_pa_clear          OTHER        1.00  \n",
       "6      90       rt_2ch_sense         2CH RT        1.00  \n",
       "7     180         rvot_sense           RVOT        1.00  \n",
       "8      30        lt_pa_sense             SA        0.73  \n",
       "9      30       lt_2ch_sense         2CH LT        1.00  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src = '../reports/EXAMPLE_series_predictions.csv'              # path to input csv containing view information\n",
    "dst = '../reports/'                                    # path to save resulting predictions\n",
    "\n",
    "# load the csv as a DataFrame using pandas\n",
    "views = pd.read_csv(src)\n",
    "views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of patients: 1\n",
      "Number of series: 10\n"
     ]
    }
   ],
   "source": [
    "print('Number of patients: {}'.format(len(views['Patient ID'].unique())))\n",
    "print('Number of series: {}'.format(len(views['Series ID'].unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The available views for single patient can be found using the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available patients: ['CHD1055302']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient ID</th>\n",
       "      <th>Series ID</th>\n",
       "      <th>Series Number</th>\n",
       "      <th>Frames</th>\n",
       "      <th>Series Description</th>\n",
       "      <th>Predicted View</th>\n",
       "      <th>Confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CHD1055302</td>\n",
       "      <td>2.16.124.113543.6006.99.4489543484581785604</td>\n",
       "      <td>1501</td>\n",
       "      <td>90</td>\n",
       "      <td>flow_bh_ao_sense</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CHD1055302</td>\n",
       "      <td>2.16.124.113543.6006.99.4545974342301296934</td>\n",
       "      <td>1101</td>\n",
       "      <td>480</td>\n",
       "      <td>sa_sense</td>\n",
       "      <td>SA</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CHD1055302</td>\n",
       "      <td>2.16.124.113543.6006.99.4513285645466080530</td>\n",
       "      <td>1401</td>\n",
       "      <td>80</td>\n",
       "      <td>4ch_sense</td>\n",
       "      <td>4CH</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHD1055302</td>\n",
       "      <td>2.16.124.113543.6006.99.4544301574540994342</td>\n",
       "      <td>1201</td>\n",
       "      <td>60</td>\n",
       "      <td>lvot_sense</td>\n",
       "      <td>LVOT</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CHD1055302</td>\n",
       "      <td>2.16.124.113543.6006.99.4575318287899584458</td>\n",
       "      <td>701</td>\n",
       "      <td>120</td>\n",
       "      <td>4ch_sense</td>\n",
       "      <td>4CH</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CHD1055302</td>\n",
       "      <td>2.16.124.113543.6006.99.4557103526600474423</td>\n",
       "      <td>501</td>\n",
       "      <td>12</td>\n",
       "      <td>bb_-_ax_pa_clear</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CHD1055302</td>\n",
       "      <td>2.16.124.113543.6006.99.4492460316146916281</td>\n",
       "      <td>901</td>\n",
       "      <td>90</td>\n",
       "      <td>rt_2ch_sense</td>\n",
       "      <td>2CH RT</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CHD1055302</td>\n",
       "      <td>2.16.124.113543.6006.99.4569864505174670623</td>\n",
       "      <td>801</td>\n",
       "      <td>180</td>\n",
       "      <td>rvot_sense</td>\n",
       "      <td>RVOT</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CHD1055302</td>\n",
       "      <td>2.16.124.113543.6006.99.7493418895009265798</td>\n",
       "      <td>1801</td>\n",
       "      <td>30</td>\n",
       "      <td>lt_pa_sense</td>\n",
       "      <td>SA</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CHD1055302</td>\n",
       "      <td>2.16.124.113543.6006.99.4488755540510057828</td>\n",
       "      <td>601</td>\n",
       "      <td>30</td>\n",
       "      <td>lt_2ch_sense</td>\n",
       "      <td>2CH LT</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Patient ID                                    Series ID  Series Number  \\\n",
       "0  CHD1055302  2.16.124.113543.6006.99.4489543484581785604           1501   \n",
       "1  CHD1055302  2.16.124.113543.6006.99.4545974342301296934           1101   \n",
       "2  CHD1055302  2.16.124.113543.6006.99.4513285645466080530           1401   \n",
       "3  CHD1055302  2.16.124.113543.6006.99.4544301574540994342           1201   \n",
       "4  CHD1055302  2.16.124.113543.6006.99.4575318287899584458            701   \n",
       "5  CHD1055302  2.16.124.113543.6006.99.4557103526600474423            501   \n",
       "6  CHD1055302  2.16.124.113543.6006.99.4492460316146916281            901   \n",
       "7  CHD1055302  2.16.124.113543.6006.99.4569864505174670623            801   \n",
       "8  CHD1055302  2.16.124.113543.6006.99.7493418895009265798           1801   \n",
       "9  CHD1055302  2.16.124.113543.6006.99.4488755540510057828            601   \n",
       "\n",
       "   Frames Series Description Predicted View  Confidence  \n",
       "0      90   flow_bh_ao_sense          OTHER        1.00  \n",
       "1     480           sa_sense             SA        1.00  \n",
       "2      80          4ch_sense            4CH        1.00  \n",
       "3      60         lvot_sense           LVOT        1.00  \n",
       "4     120          4ch_sense            4CH        1.00  \n",
       "5      12   bb_-_ax_pa_clear          OTHER        1.00  \n",
       "6      90       rt_2ch_sense         2CH RT        1.00  \n",
       "7     180         rvot_sense           RVOT        1.00  \n",
       "8      30        lt_pa_sense             SA        0.73  \n",
       "9      30       lt_2ch_sense         2CH LT        1.00  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patients = views['Patient ID'].unique()\n",
    "print('Available patients: {}'.format(patients))\n",
    "\n",
    "# select the first patient\n",
    "patient_df = views.loc[views['Patient ID'] == patients[0]]\n",
    "patient_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient ID</th>\n",
       "      <th>Series ID</th>\n",
       "      <th>Series Number</th>\n",
       "      <th>Frames</th>\n",
       "      <th>Series Description</th>\n",
       "      <th>Predicted View</th>\n",
       "      <th>Confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CHD1055302</td>\n",
       "      <td>2.16.124.113543.6006.99.4545974342301296934</td>\n",
       "      <td>1101</td>\n",
       "      <td>480</td>\n",
       "      <td>sa_sense</td>\n",
       "      <td>SA</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CHD1055302</td>\n",
       "      <td>2.16.124.113543.6006.99.4513285645466080530</td>\n",
       "      <td>1401</td>\n",
       "      <td>80</td>\n",
       "      <td>4ch_sense</td>\n",
       "      <td>4CH</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CHD1055302</td>\n",
       "      <td>2.16.124.113543.6006.99.4575318287899584458</td>\n",
       "      <td>701</td>\n",
       "      <td>120</td>\n",
       "      <td>4ch_sense</td>\n",
       "      <td>4CH</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CHD1055302</td>\n",
       "      <td>2.16.124.113543.6006.99.7493418895009265798</td>\n",
       "      <td>1801</td>\n",
       "      <td>30</td>\n",
       "      <td>lt_pa_sense</td>\n",
       "      <td>SA</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Patient ID                                    Series ID  Series Number  \\\n",
       "1  CHD1055302  2.16.124.113543.6006.99.4545974342301296934           1101   \n",
       "2  CHD1055302  2.16.124.113543.6006.99.4513285645466080530           1401   \n",
       "4  CHD1055302  2.16.124.113543.6006.99.4575318287899584458            701   \n",
       "8  CHD1055302  2.16.124.113543.6006.99.7493418895009265798           1801   \n",
       "\n",
       "   Frames Series Description Predicted View  Confidence  \n",
       "1     480           sa_sense             SA        1.00  \n",
       "2      80          4ch_sense            4CH        1.00  \n",
       "4     120          4ch_sense            4CH        1.00  \n",
       "8      30        lt_pa_sense             SA        0.73  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select the 4CH and SA views for this patient\n",
    "input_df = patient_df.loc[(patient_df['Predicted View'].isin(['SA','4CH']))]\n",
    "input_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient ID</th>\n",
       "      <th>Series ID</th>\n",
       "      <th>Series Number</th>\n",
       "      <th>Frames</th>\n",
       "      <th>Series Description</th>\n",
       "      <th>Predicted View</th>\n",
       "      <th>Confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CHD1055302</td>\n",
       "      <td>2.16.124.113543.6006.99.4545974342301296934</td>\n",
       "      <td>1101</td>\n",
       "      <td>480</td>\n",
       "      <td>sa_sense</td>\n",
       "      <td>SA</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CHD1055302</td>\n",
       "      <td>2.16.124.113543.6006.99.4513285645466080530</td>\n",
       "      <td>1401</td>\n",
       "      <td>80</td>\n",
       "      <td>4ch_sense</td>\n",
       "      <td>4CH</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CHD1055302</td>\n",
       "      <td>2.16.124.113543.6006.99.4575318287899584458</td>\n",
       "      <td>701</td>\n",
       "      <td>120</td>\n",
       "      <td>4ch_sense</td>\n",
       "      <td>4CH</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Patient ID                                    Series ID  Series Number  \\\n",
       "1  CHD1055302  2.16.124.113543.6006.99.4545974342301296934           1101   \n",
       "2  CHD1055302  2.16.124.113543.6006.99.4513285645466080530           1401   \n",
       "4  CHD1055302  2.16.124.113543.6006.99.4575318287899584458            701   \n",
       "\n",
       "   Frames Series Description Predicted View  Confidence  \n",
       "1     480           sa_sense             SA         1.0  \n",
       "2      80          4ch_sense            4CH         1.0  \n",
       "4     120          4ch_sense            4CH         1.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exclude low confidence predictions\n",
    "input_df = input_df.loc[(input_df['Confidence'] > 0.95)]\n",
    "input_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading DICOM files for desired series\n",
    "\n",
    "Now that we have identified some potential series, we can go ahead and load the dicom files for these series. The code below iterates over all the dicom files in the input directory, selecting each desired series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file list...\n",
      "1172 files found.\n"
     ]
    }
   ],
   "source": [
    "src = '../data/example/CHD10553/' #UPDATE with correct patient information\n",
    "\n",
    "print('Reading file list...')\n",
    "unsortedList = []\n",
    "for root, dirs, files in os.walk(src):\n",
    "    for file in files: \n",
    "        if \".dcm\" in file: # exclude non-dicoms, good for messy folders\n",
    "            unsortedList.append(os.path.join(root, file))\n",
    "\n",
    "print('%s files found.' % len(unsortedList))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following code, we will load the all of the images for the file list we just generated. This images will be placed into a pandas dataframe as a placeholder with the corresponding series and instance information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(string):\n",
    "    # clean and standardize text descriptions, which makes searching files easier\n",
    "    forbidden_symbols = [\"*\", \".\", \",\", \"\\\"\", \"\\\\\", \"/\", \"|\", \"[\", \"]\", \":\", \";\", \" \"]\n",
    "    for symbol in forbidden_symbols:\n",
    "        string = string.replace(symbol, \"_\") # replace everything with an underscore\n",
    "    \n",
    "    return string.lower() \n",
    "\n",
    "def get_series_headers(dicom_list, series_list):\n",
    "    # load dicom files for each series in a list of series IDs. \n",
    "    output = []\n",
    "    \n",
    "    for dicom_loc in tqdm(dicom_list):\n",
    "        # read dicom file and return header information and image\n",
    "        ds = pydicom.read_file(dicom_loc, force=True)\n",
    "        seriesInstanceUID = ds.get(\"SeriesInstanceUID\",\"NA\")\n",
    "        \n",
    "        if seriesInstanceUID in series_list:\n",
    "            # get patient, study, and series information\n",
    "            patientID = clean_text(ds.get(\"PatientID\", \"NA\"))\n",
    "            seriesInstanceUID = ds.get(\"SeriesInstanceUID\",\"NA\")\n",
    "            instanceNumber = str(ds.get(\"InstanceNumber\",\"0\"))\n",
    "\n",
    "            # load image data\n",
    "            array = ds.pixel_array\n",
    "    \n",
    "            output.append([patientID, dicom_loc, seriesInstanceUID, instanceNumber, array])\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1172/1172 [00:05<00:00, 223.65it/s]\n"
     ]
    }
   ],
   "source": [
    "output = get_series_headers(unsortedList, list(input_df['Series ID']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pd.DataFrame(output, columns = ['Patient ID', 'Filepath', 'Series ID', 'Instance ID', 'Array'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient ID</th>\n",
       "      <th>Filepath</th>\n",
       "      <th>Series ID</th>\n",
       "      <th>Instance ID</th>\n",
       "      <th>Array</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chd1055302</td>\n",
       "      <td>../data/example/CHD10553/CHD1055302\\CAP_CHD105...</td>\n",
       "      <td>2.16.124.113543.6006.99.4513285645466080530</td>\n",
       "      <td>42</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chd1055302</td>\n",
       "      <td>../data/example/CHD10553/CHD1055302\\CAP_CHD105...</td>\n",
       "      <td>2.16.124.113543.6006.99.4513285645466080530</td>\n",
       "      <td>23</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chd1055302</td>\n",
       "      <td>../data/example/CHD10553/CHD1055302\\CAP_CHD105...</td>\n",
       "      <td>2.16.124.113543.6006.99.4513285645466080530</td>\n",
       "      <td>54</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chd1055302</td>\n",
       "      <td>../data/example/CHD10553/CHD1055302\\CAP_CHD105...</td>\n",
       "      <td>2.16.124.113543.6006.99.4513285645466080530</td>\n",
       "      <td>33</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chd1055302</td>\n",
       "      <td>../data/example/CHD10553/CHD1055302\\CAP_CHD105...</td>\n",
       "      <td>2.16.124.113543.6006.99.4575318287899584458</td>\n",
       "      <td>16</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>chd1055302</td>\n",
       "      <td>../data/example/CHD10553/CHD1055302\\CAP_CHD105...</td>\n",
       "      <td>2.16.124.113543.6006.99.4545974342301296934</td>\n",
       "      <td>383</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>chd1055302</td>\n",
       "      <td>../data/example/CHD10553/CHD1055302\\CAP_CHD105...</td>\n",
       "      <td>2.16.124.113543.6006.99.4545974342301296934</td>\n",
       "      <td>410</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>chd1055302</td>\n",
       "      <td>../data/example/CHD10553/CHD1055302\\CAP_CHD105...</td>\n",
       "      <td>2.16.124.113543.6006.99.4545974342301296934</td>\n",
       "      <td>51</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>chd1055302</td>\n",
       "      <td>../data/example/CHD10553/CHD1055302\\CAP_CHD105...</td>\n",
       "      <td>2.16.124.113543.6006.99.4545974342301296934</td>\n",
       "      <td>361</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>chd1055302</td>\n",
       "      <td>../data/example/CHD10553/CHD1055302\\CAP_CHD105...</td>\n",
       "      <td>2.16.124.113543.6006.99.4545974342301296934</td>\n",
       "      <td>143</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>680 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Patient ID                                           Filepath  \\\n",
       "0    chd1055302  ../data/example/CHD10553/CHD1055302\\CAP_CHD105...   \n",
       "1    chd1055302  ../data/example/CHD10553/CHD1055302\\CAP_CHD105...   \n",
       "2    chd1055302  ../data/example/CHD10553/CHD1055302\\CAP_CHD105...   \n",
       "3    chd1055302  ../data/example/CHD10553/CHD1055302\\CAP_CHD105...   \n",
       "4    chd1055302  ../data/example/CHD10553/CHD1055302\\CAP_CHD105...   \n",
       "..          ...                                                ...   \n",
       "675  chd1055302  ../data/example/CHD10553/CHD1055302\\CAP_CHD105...   \n",
       "676  chd1055302  ../data/example/CHD10553/CHD1055302\\CAP_CHD105...   \n",
       "677  chd1055302  ../data/example/CHD10553/CHD1055302\\CAP_CHD105...   \n",
       "678  chd1055302  ../data/example/CHD10553/CHD1055302\\CAP_CHD105...   \n",
       "679  chd1055302  ../data/example/CHD10553/CHD1055302\\CAP_CHD105...   \n",
       "\n",
       "                                       Series ID Instance ID  \\\n",
       "0    2.16.124.113543.6006.99.4513285645466080530          42   \n",
       "1    2.16.124.113543.6006.99.4513285645466080530          23   \n",
       "2    2.16.124.113543.6006.99.4513285645466080530          54   \n",
       "3    2.16.124.113543.6006.99.4513285645466080530          33   \n",
       "4    2.16.124.113543.6006.99.4575318287899584458          16   \n",
       "..                                           ...         ...   \n",
       "675  2.16.124.113543.6006.99.4545974342301296934         383   \n",
       "676  2.16.124.113543.6006.99.4545974342301296934         410   \n",
       "677  2.16.124.113543.6006.99.4545974342301296934          51   \n",
       "678  2.16.124.113543.6006.99.4545974342301296934         361   \n",
       "679  2.16.124.113543.6006.99.4545974342301296934         143   \n",
       "\n",
       "                                                 Array  \n",
       "0    [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n",
       "1    [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n",
       "2    [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n",
       "3    [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n",
       "4    [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n",
       "..                                                 ...  \n",
       "675  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n",
       "676  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n",
       "677  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n",
       "678  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n",
       "679  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n",
       "\n",
       "[680 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating 2D + Time Volumes\n",
    "\n",
    "Now that all of the images have been loaded, we need to format them into a 2D + time volume that the neural network can use as an input. The images are opened according to the window width and level specified in the DICOM headers. The frames are placed into the volume according to the instance number. The neural networks for this notebook were trained on series of the format (batch_size, 30, 224, 224, 3); as a result, only series with 30 frames per slice location will be included. The following functions will complete this task for us: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define windowing function \n",
    "def windowing(image, window_center, window_width):\n",
    "    \"\"\"Clip an array to the appropriate range given a window width and level\"\"\"\n",
    "    # calculate min and max pixel values\n",
    "    min_value = window_center - window_width / 2\n",
    "    max_value = window_center + window_width / 2\n",
    "    \n",
    "    # clip values to appropriate window\n",
    "    return np.clip(image, min_value, max_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def volume_from_instance_idx(series_dcm_list):\n",
    "    \"\"\"\n",
    "    Loads a 3D dicom image volume with the phase + slice (or instances if phases are unavailable) defining each volume\n",
    "    :param inpath: list of dicoms in each series\n",
    "    :return: (slices, phases, 224, 224, 1) array\n",
    "    \"\"\"\n",
    "\n",
    "    # save image dimensions, window, and tags from the first image in the list\n",
    "    imshape = (224,224)\n",
    "    window_center = series_dcm_list[0][0x0028, 0x1050].value\n",
    "    window_width = series_dcm_list[0][0x0028, 0x1051].value\n",
    "    tags = [series_dcm_list[0].SeriesNumber]\n",
    "    \n",
    "    # find the number of frames in the series (ideally from the dicom header)\n",
    "    try:\n",
    "        number_of_frames = series_dcm_list[0][0x0020, 0x1002].value\n",
    "    except:\n",
    "        try: \n",
    "            phases = series_dcm_list[0][0x2001, 0x1017].value\n",
    "            slices = series_dcm_list[0][0x2001, 0x1018].value\n",
    "            number_of_frames = phases * slices\n",
    "        except:\n",
    "            number_of_frames = len(series_dcm_list)\n",
    "        \n",
    "    if number_of_frames % 30 == 0:\n",
    "        \n",
    "        # store slice locations in list\n",
    "        slice_locations = [dcm[0x0020, 0x1041].value for dcm in series_dcm_list]\n",
    "        \n",
    "        # make map to convert slice locations into consecutive integers\n",
    "        map_dict = {}\n",
    "        for i, loc in enumerate(sorted(list(set(slice_locations)))):\n",
    "            map_dict[loc] = i\n",
    "        \n",
    "        # create a volume of the appropriate size\n",
    "        vol = np.zeros((int(len(set(slice_locations))), 30, imshape[0], imshape[1], 1), dtype=np.uint16)\n",
    "        \n",
    "        reversed_map = False \n",
    "        \n",
    "        # iterate through dcms and assign pixel_array to the appropriate location in the slice\n",
    "        for dcm in series_dcm_list:\n",
    "            slice_loc = dcm[0x0020, 0x1041].value\n",
    "            slice_idx = map_dict[slice_loc]\n",
    "            phase_idx = int(dcm.InstanceNumber - 30 * slice_idx) - 1         # instanceNumber - 30 * slice_iterator = phase location\n",
    "            #print('Calculated phase index of {} and slice of {}'.format(phase_idx, slice_idx))\n",
    "            \n",
    "            if phase_idx > 30 or phase_idx < 0:\n",
    "                \n",
    "                # will need to reverse the order of slice locations\n",
    "                map_dict = {}\n",
    "                for i, loc in enumerate(reversed(sorted(list(set(slice_locations))))):\n",
    "                    map_dict[loc] = i\n",
    "                    \n",
    "                reversed_map = True\n",
    "                    \n",
    "                # reiterate through dcms\n",
    "                for dcm in series_dcm_list:\n",
    "                    slice_loc = dcm[0x0020, 0x1041].value\n",
    "                    slice_idx = map_dict[slice_loc]\n",
    "                    phase_idx = int(dcm.InstanceNumber - 30 * slice_idx) - 1 \n",
    "                    \n",
    "                    img = windowing(dcm.pixel_array, window_center, window_width).astype(np.uint16)\n",
    "                    resized = cv2.resize(img, dsize=(224, 224), interpolation=cv2.INTER_CUBIC)\n",
    "                    # insert into volume\n",
    "                    vol[slice_idx, phase_idx, :, :, 0] = np.copy(resized)\n",
    "            \n",
    "            elif reversed_map == False:\n",
    "                           \n",
    "                img = windowing(dcm.pixel_array, window_center, window_width).astype(np.uint16)\n",
    "                resized = cv2.resize(img, dsize=(224, 224), interpolation=cv2.INTER_CUBIC)\n",
    "                # insert into volume\n",
    "                vol[slice_idx, phase_idx, :, :, 0] = np.copy(resized)\n",
    "            \n",
    "            else:\n",
    "                break\n",
    "            \n",
    "        print('Created volume of size {}'.format(vol.shape))\n",
    "        \n",
    "        return vol     \n",
    "     \n",
    "    else:\n",
    "        print(\"Series does not contain enough frames/phases: skipping series {}\".format(tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Generator\n",
    "\n",
    "The trained neural networks expect an input of the size (batch_size, 30, 224, 224, 3). For a given batch, the input contains 30 time points of 3-channel images, where the channels are the t, t+1, and t+2 frames for a given series. To produce this input, we define a generator below that will accept the volumes generated above and produce the desired inputs. Furthermore, to help the networks reliably identify the correct end-systolic phase frame, regardless of which temporal position it occurs at in the series, the 30 frame series is \"rolled\" forward five times. For example, in a series where the ES phase occurs in the 8th frame as shown below: \n",
    "\n",
    "0, 1, 2, 3, 4, 5, 6, 7, 8 (ES Phase), 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29,\n",
    "\n",
    "will be rolled forward 4 times to also produce the following inputs: \n",
    "\n",
    "28, 29, 0, 1, 2, 3, 4, 5, 6, 7, 8 (ES Phase), 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, \n",
    "\n",
    "26, 27, 28, 29, 0, 1, 2, 3, 4, 5, 6, 7, 8 (ES Phase), 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, \n",
    "\n",
    "24, 25, 26, 27, 28, 29, 0, 1, 2, 3, 4, 5, 6, 7, 8 (ES Phase), 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, \n",
    "\n",
    "22, 23, 24, 25, 26, 27, 28, 29, 0, 1, 2, 3, 4, 5, 6, 7, 8 (ES Phase), 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21. \n",
    "\n",
    "\n",
    "Ideally, the network will predict that the ES phase occurs at the 8th, 10th, 12th, 14th, and 16th index for the above inputs. These responses will then be rolled backwards and averaged to produce a final prediction. \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(images, counter=0, window_size = 30):\n",
    "    \" Data generator for 2D + time images of shape (None, batch_sz, 30, 224, 224, 1)\"\n",
    "    keys = [x for x in range(images.shape[0])]\n",
    "    \n",
    "    while True:\n",
    "        input_images = np.zeros((5, window_size, 224, 224, 3))\n",
    "        #np.random.shuffle(keys)\n",
    "        \n",
    "        for i in range(5):\n",
    "            # load images and concatenate along batch axis\n",
    "            imgs = np.array(images[keys[counter], ...]).astype(np.float32)\n",
    "            imgs = np.roll(imgs, i*2, 0)\n",
    "            \n",
    "            frame2 = np.roll(imgs, -1, 0) # get next 2 frames (t+1, t+2) to append to the original image\n",
    "            frame3 = np.roll(imgs, -2, 0)\n",
    "            imgs = tf.squeeze(np.stack((imgs, frame2, frame3), axis=3))\n",
    "            \n",
    "            imgs = np.expand_dims(imgs, 0)\n",
    "            input_images[i] = np.concatenate(imgs, axis=0)\n",
    "            \n",
    "            # normalize images\n",
    "            input_images[i] = (input_images[i] - np.min(input_images[i]))\n",
    "            \n",
    "            max_value = np.max(input_images[i])\n",
    "            if max_value > 0:\n",
    "                input_images[i] = (input_images[i] / max_value ) * 255.\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "            input_images[i] = tf.keras.applications.resnet50.preprocess_input(input_images[i])\n",
    "        \n",
    "        yield (input_images.astype(np.float32))\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the Trained Model\n",
    "\n",
    "The previously trained models include a ResNet5-LSTM network and a VGG19-LSTM network. These models can be loaded using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed (TimeDistri (None, 30, 7, 7, 2048)    23587712  \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 30, 2048)          0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 30, 512)           5244928   \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 30, 512)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 30, 512)           2099200   \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 30, 512)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_4 (TimeDist (None, 30, 128)           65664     \n",
      "_________________________________________________________________\n",
      "time_distributed_5 (TimeDist (None, 30, 128)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_6 (TimeDist (None, 30, 1)             129       \n",
      "=================================================================\n",
      "Total params: 30,997,633\n",
      "Trainable params: 30,944,513\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "MODELPATH = '../models/phases/resnet50_lstm.hdf5'\n",
    "model = tf.keras.models.load_model(MODELPATH)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running the Complete Analysis\n",
    "\n",
    "Now that we have defined the necessary functions, we can create the volumes for each 4CH and SA series that was found for the desired patient above and make a prediction of the ES phase using the trained neural network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series does not contain enough frames/phases: skipping series [\"1401\"]\n",
      "Created volume of size (4, 30, 224, 224, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [01:08<00:00, 17.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created volume of size (16, 30, 224, 224, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [04:11<00:00, 15.73s/it]\n"
     ]
    }
   ],
   "source": [
    "volumes = []\n",
    "if 'ES Phase Prediction' not in input_df.keys():\n",
    "    input_df['ES Phase Prediction'] = \"\"\n",
    "    \n",
    "for series in out['Series ID'].unique():\n",
    "    \n",
    "    new = out.loc[out['Series ID'] == series]\n",
    "    \n",
    "    files = new['Filepath']\n",
    "    dcm_list = []\n",
    "    \n",
    "    # iterate through files in current list\n",
    "    for file in files:\n",
    "        # check to ensure file is a valid dcm file\n",
    "        try:\n",
    "            dcm = pydicom.dcmread(file)\n",
    "            dcm_list.append(dcm)\n",
    "\n",
    "        except:\n",
    "            # traceback.print_exc()\n",
    "            pass\n",
    "        \n",
    "    vol = volume_from_instance_idx(dcm_list)\n",
    "    \n",
    "    if vol is not None: \n",
    "        pred_es = []\n",
    "        for j in tqdm(range(vol.shape[0])):\n",
    "            predictions = np.zeros((5,30))\n",
    "            images = next(generator(vol, counter=j)) # for each volume, generate the corresponding input\n",
    "\n",
    "            for i, img in enumerate(images):\n",
    "                preds = model.predict_on_batch(tf.expand_dims(img,0))\n",
    "                predictions[i,:] = np.roll(tf.squeeze(preds), -i*2, 0) # roll predictions backwards for each sequential input\n",
    "\n",
    "            pred_es.append(np.argmax(np.mean(predictions, axis=0)))\n",
    "            \n",
    "        # add prediction to dataframe loaded from csv previously\n",
    "        input_df.loc[input_df['Series ID'] == series, ['ES Phase Prediction']] = np.median(pred_es)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ES phase predictions have been added to the dataframe with the patient, series, and view information, as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient ID</th>\n",
       "      <th>Series ID</th>\n",
       "      <th>Series Number</th>\n",
       "      <th>Frames</th>\n",
       "      <th>Series Description</th>\n",
       "      <th>Predicted View</th>\n",
       "      <th>Confidence</th>\n",
       "      <th>ES Phase Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CHD1055302</td>\n",
       "      <td>2.16.124.113543.6006.99.4545974342301296934</td>\n",
       "      <td>1101</td>\n",
       "      <td>480</td>\n",
       "      <td>sa_sense</td>\n",
       "      <td>SA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CHD1055302</td>\n",
       "      <td>2.16.124.113543.6006.99.4513285645466080530</td>\n",
       "      <td>1401</td>\n",
       "      <td>80</td>\n",
       "      <td>4ch_sense</td>\n",
       "      <td>4CH</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CHD1055302</td>\n",
       "      <td>2.16.124.113543.6006.99.4575318287899584458</td>\n",
       "      <td>701</td>\n",
       "      <td>120</td>\n",
       "      <td>4ch_sense</td>\n",
       "      <td>4CH</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Patient ID                                    Series ID  Series Number  \\\n",
       "1  CHD1055302  2.16.124.113543.6006.99.4545974342301296934           1101   \n",
       "2  CHD1055302  2.16.124.113543.6006.99.4513285645466080530           1401   \n",
       "4  CHD1055302  2.16.124.113543.6006.99.4575318287899584458            701   \n",
       "\n",
       "   Frames Series Description Predicted View  Confidence ES Phase Prediction  \n",
       "1     480           sa_sense             SA         1.0                  13  \n",
       "2      80          4ch_sense            4CH         1.0                      \n",
       "4     120          4ch_sense            4CH         1.0                  13  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save this dataframe to a new csv file\n",
    "input_df.to_csv(dst + '{}_phase_predictions.csv'.format(input_df.iloc[0]['Patient ID']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0 Multiple Patients\n",
    "\n",
    "To run the complete analysis over multiple patients, use the following code. To start, select the desired parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### PARAMETERS ####\n",
    "csv_src = '../reports/EXAMPLE_series_predictions.csv'       # path to input csv containing view information\n",
    "src = '../data/example/'                                # path to raw dicom files\n",
    "dst = '../reports/'                                        # path to save resulting predictions\n",
    "\n",
    "MODELPATH = '../models/phases/resnet50_lstm.hdf5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If not already run above, define the necessary functions for the analysis by running the code block below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(string):\n",
    "    # clean and standardize text descriptions, which makes searching files easier\n",
    "    forbidden_symbols = [\"*\", \".\", \",\", \"\\\"\", \"\\\\\", \"/\", \"|\", \"[\", \"]\", \":\", \";\", \" \"]\n",
    "    for symbol in forbidden_symbols:\n",
    "        string = string.replace(symbol, \"_\") # replace everything with an underscore\n",
    "    \n",
    "    return string.lower() \n",
    "\n",
    "def get_series_headers(dicom_list, series_list):\n",
    "    # load dicom files for each series in a list of series IDs. \n",
    "    output = []\n",
    "    \n",
    "    for dicom_loc in dicom_list:\n",
    "        # read dicom file and return header information and image\n",
    "        ds = pydicom.read_file(dicom_loc, force=True)\n",
    "        seriesInstanceUID = ds.get(\"SeriesInstanceUID\",\"NA\")\n",
    "        \n",
    "        if seriesInstanceUID in series_list:\n",
    "            # get patient, study, and series information\n",
    "            patientID = clean_text(ds.get(\"PatientID\", \"NA\"))\n",
    "            seriesInstanceUID = ds.get(\"SeriesInstanceUID\",\"NA\")\n",
    "            instanceNumber = str(ds.get(\"InstanceNumber\",\"0\"))\n",
    "\n",
    "            # load image data\n",
    "            array = ds.pixel_array\n",
    "    \n",
    "            output.append([patientID, dicom_loc, seriesInstanceUID, instanceNumber, array])\n",
    "    \n",
    "    return output\n",
    "\n",
    "def windowing(image, window_center, window_width):\n",
    "    \"\"\"Clip an array to the appropriate range given a window width and level\"\"\"\n",
    "    # calculate min and max pixel values\n",
    "    min_value = window_center - window_width / 2\n",
    "    max_value = window_center + window_width / 2\n",
    "    \n",
    "    # clip values to appropriate window\n",
    "    return np.clip(image, min_value, max_value)\n",
    "\n",
    "def volume_from_instance_idx(series_dcm_list):\n",
    "    \"\"\"\n",
    "    Loads a 3D dicom image volume with the phase + slice (or instances if phases are unavailable) defining each volume\n",
    "    :param inpath: list of dicoms in each series\n",
    "    :return: (slices, phases, 224, 224, 1) array\n",
    "    \"\"\"\n",
    "\n",
    "    # save image dimensions, window, and tags from the first image in the list\n",
    "    imshape = (224,224)\n",
    "    window_center = series_dcm_list[0][0x0028, 0x1050].value\n",
    "    window_width = series_dcm_list[0][0x0028, 0x1051].value\n",
    "    tags = [series_dcm_list[0].SeriesNumber]\n",
    "    \n",
    "    # find the number of frames in the series (ideally from the dicom header)\n",
    "    try:\n",
    "        number_of_frames = series_dcm_list[0][0x0020, 0x1002].value\n",
    "    except:\n",
    "        try: \n",
    "            phases = series_dcm_list[0][0x2001, 0x1017].value\n",
    "            slices = series_dcm_list[0][0x2001, 0x1018].value\n",
    "            number_of_frames = phases * slices\n",
    "        except:\n",
    "            number_of_frames = len(series_dcm_list)\n",
    "        \n",
    "    if number_of_frames % 30 == 0: \n",
    "        \n",
    "        # store slice locations in list\n",
    "        slice_locations = [dcm[0x0020, 0x1041].value for dcm in series_dcm_list]\n",
    "        \n",
    "        # make map to convert slice locations into consecutive integers\n",
    "        map_dict = {}\n",
    "        for i, loc in enumerate(sorted(list(set(slice_locations)))):\n",
    "            map_dict[loc] = i\n",
    "        \n",
    "        # create a volume of the appropriate size\n",
    "        vol = np.zeros((int(len(set(slice_locations))), 30, imshape[0], imshape[1], 1), dtype=np.uint16)\n",
    "        \n",
    "        reversed_map = False \n",
    "        \n",
    "        # iterate through dcms and assign pixel_array to the appropriate location in the slice\n",
    "        for dcm in series_dcm_list:\n",
    "            slice_loc = dcm[0x0020, 0x1041].value\n",
    "            slice_idx = map_dict[slice_loc]\n",
    "            phase_idx = int(dcm.InstanceNumber - 30 * slice_idx) - 1         # instanceNumber - 30 * slice_iterator = phase location\n",
    "            #print('Calculated phase index of {} and slice of {}'.format(phase_idx, slice_idx))\n",
    "            \n",
    "            if phase_idx > 30 or phase_idx < 0:\n",
    "                \n",
    "                # will need to reverse the order of slice locations\n",
    "                map_dict = {}\n",
    "                for i, loc in enumerate(reversed(sorted(list(set(slice_locations))))):\n",
    "                    map_dict[loc] = i\n",
    "                    \n",
    "                reversed_map = True\n",
    "                    \n",
    "                # reiterate through dcms\n",
    "                for dcm in series_dcm_list:\n",
    "                    slice_loc = dcm[0x0020, 0x1041].value\n",
    "                    slice_idx = map_dict[slice_loc]\n",
    "                    phase_idx = int(dcm.InstanceNumber - 30 * slice_idx) - 1 \n",
    "                    \n",
    "                    img = windowing(dcm.pixel_array, window_center, window_width).astype(np.uint16)\n",
    "                    resized = cv2.resize(img, dsize=(224, 224), interpolation=cv2.INTER_CUBIC)\n",
    "                    # insert into volume\n",
    "                    vol[slice_idx, phase_idx, :, :, 0] = np.copy(resized)\n",
    "            \n",
    "            elif reversed_map == False:\n",
    "                img = windowing(dcm.pixel_array, window_center, window_width).astype(np.uint16)\n",
    "                resized = cv2.resize(img, dsize=(224, 224), interpolation=cv2.INTER_CUBIC)\n",
    "                # insert into volume\n",
    "                vol[slice_idx, phase_idx, :, :, 0] = np.copy(resized)\n",
    "            \n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        return vol     \n",
    "     \n",
    "    else:\n",
    "        pass\n",
    "        #print(\"Series does not contain enough frames/phases: skipping series {}\".format(tags))\n",
    "        \n",
    "def generator(images, counter=0, window_size = 30):\n",
    "    \" Data generator for 2D + time images of shape (None, batch_sz, 30, 224, 224, 1)\"\n",
    "    keys = [x for x in range(images.shape[0])]\n",
    "    \n",
    "    while True:\n",
    "        input_images = np.zeros((5, window_size, 224, 224, 3))\n",
    "        #np.random.shuffle(keys)\n",
    "        \n",
    "        for i in range(5):\n",
    "            # load images and concatenate along batch axis\n",
    "            imgs = np.array(images[keys[counter], ...]).astype(np.float32)\n",
    "            imgs = np.roll(imgs, i*2, 0)\n",
    "            \n",
    "            frame2 = np.roll(imgs, -1, 0) # get next 2 frames (t+1, t+2) to append to the original image\n",
    "            frame3 = np.roll(imgs, -2, 0)\n",
    "            imgs = tf.squeeze(np.stack((imgs, frame2, frame3), axis=3))\n",
    "            \n",
    "            imgs = np.expand_dims(imgs, 0)\n",
    "            input_images[i] = np.concatenate(imgs, axis=0)\n",
    "            \n",
    "            # normalize images\n",
    "            input_images[i] = (input_images[i] - np.min(input_images[i]))\n",
    "            \n",
    "            max_value = np.max(input_images[i])\n",
    "            if max_value > 0:\n",
    "                input_images[i] = (input_images[i] / max_value ) * 255.\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "            input_images[i] = tf.keras.applications.resnet50.preprocess_input(input_images[i])\n",
    "        \n",
    "        yield (input_images.astype(np.float32))\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have selected the parameters and defined the necessary functions, we can run the ES phase prediction analysis for every patient. \n",
    "\n",
    "Note - this script assumes that the patient ID (e.g., CHD1503301) can be found in the complete path to each of that specific patient's DICOM files. For example, either of the following directory structures would be acceptable: \n",
    "\n",
    "```bash\n",
    "├── DATA\n",
    "    └── PatientID\n",
    "        ├── 1.dcm\n",
    "        ├── 2.dcm \n",
    "        ├── 3.dcm          \n",
    "        └── ...            \n",
    "```\n",
    "\n",
    "OR\n",
    "\n",
    "```bash\n",
    "├── DATA\n",
    "    └── Subdir\n",
    "        ├── *PatientID*.dcm\n",
    "        ├── *PatientID*.dcm \n",
    "        ├── *PatientID*.dcm          \n",
    "        └── ...            \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available patients: ['CHD1055302']\n",
      "Reading file list...\n",
      "Loading model from ../models/phases/resnet50_lstm.hdf5\n",
      "Running ES phase prediction for all patients!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 1/1 [05:35<00:00, 335.83s/it]\n"
     ]
    }
   ],
   "source": [
    "# load the csv as a DataFrame using pandas\n",
    "views = pd.read_csv(csv_src)\n",
    "patients = views['Patient ID'].unique()\n",
    "print('Available patients: {}'.format(patients))\n",
    "\n",
    "print('Reading file list...')\n",
    "unsortedList = []\n",
    "for root, dirs, files in os.walk(src):\n",
    "    for file in files: \n",
    "        if \".dcm\" in file: # exclude non-dicoms, good for messy folders\n",
    "            unsortedList.append(os.path.join(root, file))\n",
    "\n",
    "# load desired model\n",
    "print('Loading model from {}'.format(MODELPATH))\n",
    "model = tf.keras.models.load_model(MODELPATH)\n",
    "\n",
    "if 'ES Phase Prediction' not in views.keys():\n",
    "    views['ES Phase Prediction'] = \"\"\n",
    "\n",
    "print('Running ES phase prediction for all patients!')\n",
    "for patient in tqdm(patients):\n",
    "    patient_df = views.loc[views['Patient ID'] == patient]\n",
    "    \n",
    "    # select the 4CH and SA views for this patient\n",
    "    input_df = patient_df.loc[(patient_df['Predicted View'].isin(['SA','4CH']))]\n",
    "    \n",
    "    # exclude low confidence predictions\n",
    "    input_df = input_df.loc[(input_df['Confidence'] > 0.95)]\n",
    "    \n",
    "    # select dicom filenames corresponding to this patient\n",
    "    patient_dicom_list = [file for file in unsortedList if patient in file]\n",
    "    \n",
    "    # load headers, arrays for each desired image\n",
    "    output = get_series_headers(unsortedList, list(input_df['Series ID']))\n",
    "    out = pd.DataFrame(output, columns = ['Patient ID', 'Filepath', 'Series ID', 'Instance ID', 'Array'])\n",
    "    \n",
    "    #\n",
    "    volumes = []\n",
    "    for series in out['Series ID'].unique():\n",
    "\n",
    "        new = out.loc[out['Series ID'] == series]\n",
    "\n",
    "        files = new['Filepath']\n",
    "        dcm_list = []\n",
    "\n",
    "        # iterate through files in current list\n",
    "        for file in files:\n",
    "            # check to ensure file is a valid dcm file\n",
    "            try:\n",
    "                dcm = pydicom.dcmread(file)\n",
    "                dcm_list.append(dcm)\n",
    "\n",
    "            except:\n",
    "                # traceback.print_exc()\n",
    "                pass\n",
    "\n",
    "        vol = volume_from_instance_idx(dcm_list)\n",
    "\n",
    "        if vol is not None: \n",
    "            pred_es = []\n",
    "            for j in range(vol.shape[0]):\n",
    "                predictions = np.zeros((5,30))\n",
    "                images = next(generator(vol, counter=j)) # for each volume, generate the corresponding input\n",
    "\n",
    "                for i, img in enumerate(images):\n",
    "                    preds = model.predict_on_batch(tf.expand_dims(img,0))\n",
    "                    predictions[i,:] = np.roll(tf.squeeze(preds), -i*2, 0) # roll predictions backwards for each sequential input\n",
    "\n",
    "                pred_es.append(np.argmax(np.mean(predictions, axis=0)))\n",
    "\n",
    "            # add prediction to dataframe loaded from csv previously\n",
    "            views.loc[views['Series ID'] == series, ['ES Phase Prediction']] = np.median(pred_es)\n",
    "            \n",
    "views.to_csv(os.path.join(dst, 'ES_phase_predictions'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient ID</th>\n",
       "      <th>Series ID</th>\n",
       "      <th>Series Number</th>\n",
       "      <th>Frames</th>\n",
       "      <th>Series Description</th>\n",
       "      <th>Predicted View</th>\n",
       "      <th>Confidence</th>\n",
       "      <th>ES Phase Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CHD1055302</td>\n",
       "      <td>2.16.124.113543.6006.99.4545974342301296934</td>\n",
       "      <td>1101</td>\n",
       "      <td>480</td>\n",
       "      <td>sa_sense</td>\n",
       "      <td>SA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CHD1055302</td>\n",
       "      <td>2.16.124.113543.6006.99.4575318287899584458</td>\n",
       "      <td>701</td>\n",
       "      <td>120</td>\n",
       "      <td>4ch_sense</td>\n",
       "      <td>4CH</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Patient ID                                    Series ID  Series Number  \\\n",
       "1  CHD1055302  2.16.124.113543.6006.99.4545974342301296934           1101   \n",
       "4  CHD1055302  2.16.124.113543.6006.99.4575318287899584458            701   \n",
       "\n",
       "   Frames Series Description Predicted View  Confidence ES Phase Prediction  \n",
       "1     480           sa_sense             SA         1.0                  13  \n",
       "4     120          4ch_sense            4CH         1.0                  13  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print out generated dataframe just to see results (also saved in csv)\n",
    "views.loc[views['ES Phase Prediction'] != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n",
      "Don't know how to reset  (), please run `%reset?` for details\n"
     ]
    }
   ],
   "source": [
    "reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ucair]",
   "language": "python",
   "name": "conda-env-ucair-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
