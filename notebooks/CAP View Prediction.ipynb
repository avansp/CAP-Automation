{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cardiac MRI View Prediction\n",
    "\n",
    "The following notebook uses a trained neural network to predict the MRI view for each series in a directory of dicom files. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, import the necessary packages to run the analysis. The required libraries are pydicom, pandas, and tensorflow. The original analysis was run using python 3.6.8, pydicom 1.2.2, and tensorflow 2.4.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.6.8 |Anaconda, Inc.| (default, Feb 21 2019, 18:30:04) [MSC v.1916 64 bit (AMD64)]\n",
      "Pydicom: 1.2.2\n",
      "TensorFlow: 2.4.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pydicom # pydicom is using the gdcm package for decompression\n",
    "from multiprocessing import Pool\n",
    "import numpy as np\n",
    "import time \n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "\n",
    "print('Python: {}'.format(sys.version))\n",
    "print('Pydicom: {}'.format(pydicom.__version__))\n",
    "print('TensorFlow: {}'.format(tf.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow can be run with or without GPU support. If GPU support through tensorflow is enabled and available, the following code will display and available GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemError",
     "evalue": "GPU device not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-ce08ddae0a7d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdevice_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgpu_device_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdevice_name\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'/device:GPU:0'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m   \u001b[1;32mraise\u001b[0m \u001b[0mSystemError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'GPU device not found'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Found GPU at: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mSystemError\u001b[0m: GPU device not found"
     ]
    }
   ],
   "source": [
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If no GPU is found, or if you simply want to run the analysis using only CPU, we can configure tensorflow to only use CPU using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only use CPU for right now - Set CPU as only available physical device\n",
    "my_devices = tf.config.experimental.list_physical_devices(device_type='CPU')\n",
    "tf.config.experimental.set_visible_devices(devices= my_devices, device_type='CPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The analysis can be run over a single directory of dicom images (for one or more patients) or over a directory containing multiple subdirectories. Due to memory constraints, skip ahead to section 2.0 if your directory contains multiple patients. The code in section 2.0 runs the analysis iteratively over each subdirectory. Alternatively, if you only have one patient or a small dataset, you can run the complete analysis by running all of the code in section 1.0. \n",
    "\n",
    "The suggested directory structures for each approach are shown below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approach 1 (Section 1.0)\n",
    "\n",
    "Run the analysis over all files in a directory and subdirectories (may run into memory issues if dataset is large).\n",
    "\n",
    "```bash\n",
    "├── DATA\n",
    "    └── Patient1\n",
    "        ├── 1.dcm\n",
    "        ├── 2.dcm \n",
    "        ├── 3.dcm          \n",
    "        └── ...            \n",
    "```\n",
    "\n",
    "#### Approach 2 (Section 2.0)\n",
    "\n",
    "Run the analysis over each patient in a directory individually (i.e., analysis for patient 1, then analysis for patient 2.)\n",
    "\n",
    "```bash\n",
    "├── DATA\n",
    "    ├── Patient1\n",
    "    │   ├── 1.dcm\n",
    "    │   ├── 2.dcm \n",
    "    │   ├── 3.dcm          \n",
    "    │   └── ...   \n",
    "    └── Patient2\n",
    "        ├── 1.dcm\n",
    "        ├── 2.dcm \n",
    "        ├── 3.dcm          \n",
    "        └── ...          \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1.0 - Small Dataset and/or Single Patient\n",
    "\n",
    "Use the following code to run the analysis over all the files in a single directory. If you wish to run the analysis over each patient in a directory (recommended due to memory constraints), skip ahead to section 2.0. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters\n",
    "\n",
    "Define the desired parameters for the code in the cell below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS for the analysis\n",
    "src = \"../data/example/CHD10553/\"              # PATH to the directory containing the desired DICOM files (str)\n",
    "dst = \"../data/processed/sorted/\"                 # PATH to the output directory to save dicom files (only valid if save_dicoms = True) (str)\n",
    "\n",
    "modelname = 'ResNet50'                            # The neural network to load and used (Options: VGG19, ResNet50, or Xception)\n",
    "modelpath = '../models/'                          # PATH to the saved models (str)\n",
    "\n",
    "use_multiprocessing = False                       # Use multiprocessing to read header info (True or False)\n",
    "\n",
    "# parameters for postprocessing/saving\n",
    "csv_path = '../reports/EXAMPLE_series_predictions.csv'    # PATH to save the generated csv file (only valide if create_csv = True) (str)\n",
    "create_csv = True                                 # Save a .csv file with the series level view predictions (True or False)\n",
    "save_files = True                                 # Save dicom files to new directory (dst) (True or False)\n",
    "save_only_desired = True                          # Save only dicom files corresponding to desired views (True or False)\n",
    "confidence_value = 0.9                            # Only save series if the confidence is > a certain value (set to 0 to save all desired series, regardless of confidence) (float 0-1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cells are used to define the possible MRI view classes (n=7) and the views that are desired for cardiac modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2CH LT', '2CH RT', '4CH', 'LVOT', 'OTHER', 'RVOT', 'SA']\n"
     ]
    }
   ],
   "source": [
    "# define possible class predictions\n",
    "classLabels = ['SA', '4CH', '2CH RT', 'RVOT', 'OTHER', '2CH LT', 'LVOT']\n",
    "classes = sorted(classLabels, key = str)\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the series that are needed/desired for cardiac modeling\n",
    "desired_series = ['4CH', 'SA', '2CH RT', '2CH LT', 'LVOT', 'RVOT']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import and Load Model\n",
    "\n",
    "The following code loads the saved neural network that will be used for view prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.cast (TFOpLambda)            (None, 224, 224, 3)  0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem (Slici (None, 224, 224, 3)  0           tf.cast[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.bias_add (TFOpLambda)     (None, 224, 224, 3)  0           tf.__operators__.getitem[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "random_rotation_1 (RandomRotati (None, 224, 224, 3)  0           tf.nn.bias_add[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "random_zoom_1 (RandomZoom)      (None, 224, 224, 3)  0           random_rotation_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "random_translation_1 (RandomTra (None, 224, 224, 3)  0           random_zoom_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           random_translation_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 2048)         0           conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 7)            14343       global_average_pooling2d[0][0]   \n",
      "==================================================================================================\n",
      "Total params: 23,602,055\n",
      "Trainable params: 23,548,935\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# load the appropriate model\n",
    "if modelname == 'ResNet50':\n",
    "    MODELPATH = os.path.join(modelpath, 'ResNet50/resnet50.h5py')\n",
    "    model = tf.keras.models.load_model(MODELPATH)\n",
    "    print(model.summary())\n",
    "\n",
    "elif modelname == 'VGG19':\n",
    "    MODELPATH = os.path.join(modelpath, 'VGG19/vgg19.h5py')\n",
    "    model = tf.keras.models.load_model(MODELPATH)\n",
    "    print(model.summary())\n",
    "    \n",
    "elif modelname == 'Xception':\n",
    "    MODELPATH = os.path.join(modelpath, 'XCEPTION/xception.h5py')\n",
    "    model = tf.keras.models.load_model(MODELPATH)\n",
    "    print(model.summary())\n",
    "\n",
    "else:\n",
    "    print('Uknown model specified in parameters!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Necessary Functions\n",
    "\n",
    "Before we get started, we define a few useful functions that we will use throughout the analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(string):\n",
    "    # clean and standardize text descriptions, which makes searching files easier\n",
    "    forbidden_symbols = [\"*\", \".\", \",\", \"\\\"\", \"\\\\\", \"/\", \"|\", \"[\", \"]\", \":\", \";\", \" \"]\n",
    "    for symbol in forbidden_symbols:\n",
    "        string = string.replace(symbol, \"_\") # replace everything with an underscore\n",
    "    \n",
    "    return string.lower()  \n",
    "\n",
    "def preprocess(img):\n",
    "    # format image into tensor, standardized to 0-255\n",
    "    img = tf.cast(img, tf.float32)\n",
    "    img = tf.image.resize(tf.expand_dims(img, 2), (224,224))\n",
    "    img = tf.image.grayscale_to_rgb(img)\n",
    "    \n",
    "    # standardize\n",
    "    img = img / np.max(img)\n",
    "    img = img * 255.\n",
    "    \n",
    "    return img\n",
    "\n",
    "def predict_view(img, model=model):\n",
    "    # make prediction on a single image\n",
    "    pred = model.predict(tf.expand_dims(img, axis=0))\n",
    "    pred = tf.argmax(pred, axis=-1)\n",
    "    pred_view = classes[int(pred)]\n",
    "    \n",
    "    return pred_view\n",
    "\n",
    "def batch_predict(batch, model=model):\n",
    "    # make prediction on a batch of images\n",
    "    pred = model.predict(batch)\n",
    "    pred = tf.argmax(pred, axis=-1)\n",
    "    pred_view = [classes[int(x)] for x in pred]\n",
    "    \n",
    "    return pred_view\n",
    "\n",
    "def get_dicom_header(dicom_loc):\n",
    "    # read dicom file and return header information and image\n",
    "    ds = pydicom.read_file(dicom_loc, force=True)\n",
    "   \n",
    "    # get patient, study, and series information\n",
    "    patientID = clean_text(ds.get(\"PatientID\", \"NA\"))\n",
    "    studyDescription = clean_text(ds.get(\"StudyDescription\", \"NA\"))\n",
    "    seriesDescription = clean_text(ds.get(\"SeriesDescription\", \"NA\"))\n",
    "   \n",
    "    # generate new, standardized file name\n",
    "    modality = ds.get(\"Modality\",\"NA\")\n",
    "    studyInstanceUID = ds.get(\"StudyInstanceUID\",\"NA\")\n",
    "    seriesInstanceUID = ds.get(\"SeriesInstanceUID\",\"NA\")\n",
    "    seriesNumber = ds.get('SeriesNumber', 'NA')\n",
    "    instanceNumber = str(ds.get(\"InstanceNumber\",\"0\"))\n",
    "       \n",
    "    # load image data\n",
    "    array = ds.pixel_array\n",
    "    \n",
    "    return patientID, dicom_loc, modality, seriesInstanceUID, seriesNumber, instanceNumber, array, seriesDescription"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read DICOM Headers\n",
    "\n",
    "Before the neural network can be used to predict the MRI view, we load the necessary information from the dicom headers, such as patient IDs, series, study, modality, instance, and the corresponding raw images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file list...\n",
      "1172 files found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1172/1172 [00:42<00:00, 27.74it/s]\n"
     ]
    }
   ],
   "source": [
    "print('Reading file list...')\n",
    "unsortedList = []\n",
    "for root, dirs, files in os.walk(src):\n",
    "    for file in files: \n",
    "        if \".dcm\" in file: # exclude non-dicoms, good for messy folders\n",
    "            unsortedList.append(os.path.join(root, file))\n",
    "\n",
    "print('%s files found.' % len(unsortedList))\n",
    "\n",
    "if use_multiprocessing:\n",
    "    with Pool(os.cpu_count()) as p:\n",
    "        output = p.map(get_dicom_header, [dicom_loc for dicom_loc in unsortedList])\n",
    "        \n",
    "    print('Done!')\n",
    "\n",
    "else:\n",
    "    output = []\n",
    "    for dicom_loc in tqdm(unsortedList):\n",
    "        output.append(get_dicom_header(dicom_loc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Patient ID</th>\n",
       "      <td>chd1055302</td>\n",
       "      <td>chd1055302</td>\n",
       "      <td>chd1055302</td>\n",
       "      <td>chd1055302</td>\n",
       "      <td>chd1055302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Filename</th>\n",
       "      <td>../data/example/CHD10553/CHD1055302\\CAP_CHD105...</td>\n",
       "      <td>../data/example/CHD10553/CHD1055302\\CAP_CHD105...</td>\n",
       "      <td>../data/example/CHD10553/CHD1055302\\CAP_CHD105...</td>\n",
       "      <td>../data/example/CHD10553/CHD1055302\\CAP_CHD105...</td>\n",
       "      <td>../data/example/CHD10553/CHD1055302\\CAP_CHD105...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Modality</th>\n",
       "      <td>MR</td>\n",
       "      <td>MR</td>\n",
       "      <td>MR</td>\n",
       "      <td>MR</td>\n",
       "      <td>MR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Series ID</th>\n",
       "      <td>2.16.124.113543.6006.99.4513285645466080530</td>\n",
       "      <td>2.16.124.113543.6006.99.4513285645466080530</td>\n",
       "      <td>2.16.124.113543.6006.99.4513285645466080530</td>\n",
       "      <td>2.16.124.113543.6006.99.4513285645466080530</td>\n",
       "      <td>2.16.124.113543.6006.99.4575318287899584458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Series Number</th>\n",
       "      <td>1401</td>\n",
       "      <td>1401</td>\n",
       "      <td>1401</td>\n",
       "      <td>1401</td>\n",
       "      <td>701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Instance Number</th>\n",
       "      <td>42</td>\n",
       "      <td>23</td>\n",
       "      <td>54</td>\n",
       "      <td>33</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Img</th>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Series Description</th>\n",
       "      <td>4ch_sense</td>\n",
       "      <td>4ch_sense</td>\n",
       "      <td>4ch_sense</td>\n",
       "      <td>4ch_sense</td>\n",
       "      <td>4ch_sense</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    0  \\\n",
       "Patient ID                                                 chd1055302   \n",
       "Filename            ../data/example/CHD10553/CHD1055302\\CAP_CHD105...   \n",
       "Modality                                                           MR   \n",
       "Series ID                 2.16.124.113543.6006.99.4513285645466080530   \n",
       "Series Number                                                    1401   \n",
       "Instance Number                                                    42   \n",
       "Img                 [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "Series Description                                          4ch_sense   \n",
       "\n",
       "                                                                    1  \\\n",
       "Patient ID                                                 chd1055302   \n",
       "Filename            ../data/example/CHD10553/CHD1055302\\CAP_CHD105...   \n",
       "Modality                                                           MR   \n",
       "Series ID                 2.16.124.113543.6006.99.4513285645466080530   \n",
       "Series Number                                                    1401   \n",
       "Instance Number                                                    23   \n",
       "Img                 [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "Series Description                                          4ch_sense   \n",
       "\n",
       "                                                                    2  \\\n",
       "Patient ID                                                 chd1055302   \n",
       "Filename            ../data/example/CHD10553/CHD1055302\\CAP_CHD105...   \n",
       "Modality                                                           MR   \n",
       "Series ID                 2.16.124.113543.6006.99.4513285645466080530   \n",
       "Series Number                                                    1401   \n",
       "Instance Number                                                    54   \n",
       "Img                 [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "Series Description                                          4ch_sense   \n",
       "\n",
       "                                                                    3  \\\n",
       "Patient ID                                                 chd1055302   \n",
       "Filename            ../data/example/CHD10553/CHD1055302\\CAP_CHD105...   \n",
       "Modality                                                           MR   \n",
       "Series ID                 2.16.124.113543.6006.99.4513285645466080530   \n",
       "Series Number                                                    1401   \n",
       "Instance Number                                                    33   \n",
       "Img                 [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "Series Description                                          4ch_sense   \n",
       "\n",
       "                                                                    4  \n",
       "Patient ID                                                 chd1055302  \n",
       "Filename            ../data/example/CHD10553/CHD1055302\\CAP_CHD105...  \n",
       "Modality                                                           MR  \n",
       "Series ID                 2.16.124.113543.6006.99.4575318287899584458  \n",
       "Series Number                                                     701  \n",
       "Instance Number                                                    16  \n",
       "Img                 [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n",
       "Series Description                                          4ch_sense  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generated pandas dataframe to store information from headers\n",
    "df = pd.DataFrame(sorted(output), columns = ['Patient ID', \n",
    "                                             'Filename',\n",
    "                                             'Modality',\n",
    "                                             'Series ID', \n",
    "                                             'Series Number', \n",
    "                                             'Instance Number', \n",
    "                                             'Img', \n",
    "                                             'Series Description'])\n",
    "df.head().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make Predictions for Each Series\n",
    "\n",
    "Now that we have the header info and images, we can make predictions for each series. The following code iterates over each series and makes predictions in batches. \n",
    "\n",
    "The code generates a confidence level, which ranges from 0-1.0. This value is calculated for each series by dividing the count of the most frequent prediction by the total number of predictions. For example, if a 30 frame series has 29 correct predictions of '4CH', but one incorrect prediction of 'OTHER', the confidence would be 0.97. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [02:03<00:00, 12.32s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient ID</th>\n",
       "      <th>Series ID</th>\n",
       "      <th>Series Number</th>\n",
       "      <th>Frames</th>\n",
       "      <th>Series Description</th>\n",
       "      <th>Predicted View</th>\n",
       "      <th>Confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CHD1055302</td>\n",
       "      <td>2.16.124.113543.6006.99.4489543484581785604</td>\n",
       "      <td>1501</td>\n",
       "      <td>90</td>\n",
       "      <td>flow_bh_ao_sense</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CHD1055302</td>\n",
       "      <td>2.16.124.113543.6006.99.4545974342301296934</td>\n",
       "      <td>1101</td>\n",
       "      <td>480</td>\n",
       "      <td>sa_sense</td>\n",
       "      <td>SA</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CHD1055302</td>\n",
       "      <td>2.16.124.113543.6006.99.4513285645466080530</td>\n",
       "      <td>1401</td>\n",
       "      <td>80</td>\n",
       "      <td>4ch_sense</td>\n",
       "      <td>4CH</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHD1055302</td>\n",
       "      <td>2.16.124.113543.6006.99.4544301574540994342</td>\n",
       "      <td>1201</td>\n",
       "      <td>60</td>\n",
       "      <td>lvot_sense</td>\n",
       "      <td>LVOT</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CHD1055302</td>\n",
       "      <td>2.16.124.113543.6006.99.4575318287899584458</td>\n",
       "      <td>701</td>\n",
       "      <td>120</td>\n",
       "      <td>4ch_sense</td>\n",
       "      <td>4CH</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CHD1055302</td>\n",
       "      <td>2.16.124.113543.6006.99.4557103526600474423</td>\n",
       "      <td>501</td>\n",
       "      <td>12</td>\n",
       "      <td>bb_-_ax_pa_clear</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CHD1055302</td>\n",
       "      <td>2.16.124.113543.6006.99.4492460316146916281</td>\n",
       "      <td>901</td>\n",
       "      <td>90</td>\n",
       "      <td>rt_2ch_sense</td>\n",
       "      <td>2CH RT</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CHD1055302</td>\n",
       "      <td>2.16.124.113543.6006.99.4569864505174670623</td>\n",
       "      <td>801</td>\n",
       "      <td>180</td>\n",
       "      <td>rvot_sense</td>\n",
       "      <td>RVOT</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CHD1055302</td>\n",
       "      <td>2.16.124.113543.6006.99.7493418895009265798</td>\n",
       "      <td>1801</td>\n",
       "      <td>30</td>\n",
       "      <td>lt_pa_sense</td>\n",
       "      <td>SA</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CHD1055302</td>\n",
       "      <td>2.16.124.113543.6006.99.4488755540510057828</td>\n",
       "      <td>601</td>\n",
       "      <td>30</td>\n",
       "      <td>lt_2ch_sense</td>\n",
       "      <td>2CH LT</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Patient ID                                    Series ID  Series Number  \\\n",
       "0  CHD1055302  2.16.124.113543.6006.99.4489543484581785604           1501   \n",
       "1  CHD1055302  2.16.124.113543.6006.99.4545974342301296934           1101   \n",
       "2  CHD1055302  2.16.124.113543.6006.99.4513285645466080530           1401   \n",
       "3  CHD1055302  2.16.124.113543.6006.99.4544301574540994342           1201   \n",
       "4  CHD1055302  2.16.124.113543.6006.99.4575318287899584458            701   \n",
       "5  CHD1055302  2.16.124.113543.6006.99.4557103526600474423            501   \n",
       "6  CHD1055302  2.16.124.113543.6006.99.4492460316146916281            901   \n",
       "7  CHD1055302  2.16.124.113543.6006.99.4569864505174670623            801   \n",
       "8  CHD1055302  2.16.124.113543.6006.99.7493418895009265798           1801   \n",
       "9  CHD1055302  2.16.124.113543.6006.99.4488755540510057828            601   \n",
       "\n",
       "   Frames Series Description Predicted View  Confidence  \n",
       "0      90   flow_bh_ao_sense          OTHER        1.00  \n",
       "1     480           sa_sense             SA        1.00  \n",
       "2      80          4ch_sense            4CH        1.00  \n",
       "3      60         lvot_sense           LVOT        1.00  \n",
       "4     120          4ch_sense            4CH        1.00  \n",
       "5      12   bb_-_ax_pa_clear          OTHER        1.00  \n",
       "6      90       rt_2ch_sense         2CH RT        1.00  \n",
       "7     180         rvot_sense           RVOT        1.00  \n",
       "8      30        lt_pa_sense             SA        0.73  \n",
       "9      30       lt_2ch_sense         2CH LT        1.00  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_series = []\n",
    "# make predictions and calculate confidence values\n",
    "for series in tqdm(set(df['Series ID'])):\n",
    "    new = df[df['Series ID'] == series]\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices([preprocess(x) for x in new['Img'].values])\n",
    "    dataset = (dataset\n",
    "             .batch(16)\n",
    "             .prefetch(tf.data.experimental.AUTOTUNE))\n",
    "    \n",
    "    # record info for this series\n",
    "    patient_id = new['Patient ID'].iloc[0]\n",
    "    series_num = new['Series Number'].iloc[0]\n",
    "    series_desc = new['Series Description'].iloc[0]\n",
    "    frames = len(new)\n",
    "    \n",
    "    # make predictions over images\n",
    "    views = batch_predict(dataset, model)\n",
    "\n",
    "    # find unique predictions and confidence for that series\n",
    "    u, count = np.unique(views, return_counts=True)\n",
    "    count_sort_ind = np.argsort(-count)\n",
    "    pred = u[count_sort_ind][0]\n",
    "    conf = np.round(np.max(count) / np.sum(count), 2)\n",
    "        \n",
    "    output_series.append([patient_id.upper(), series, series_num, frames, series_desc, pred, conf])\n",
    "    \n",
    "output_series_df = pd.DataFrame(output_series, columns=['Patient ID', 'Series ID', 'Series Number', 'Frames', 'Series Description', 'Predicted View', 'Confidence'])\n",
    "output_series_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Predictions\n",
    "\n",
    "Now that the predictions have been made, we can save the pandas dataframe containing the predicted view for each series to a .csv file and the dicom files of the desired views for cardiac modeling to a new directory, depending on the parameters that were specified above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving .csv file with series predictions and info\n",
      "Done!\n",
      "Saving dicom files to new folder...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:25<00:00,  2.51s/it]\n"
     ]
    }
   ],
   "source": [
    "if create_csv:\n",
    "    print('Saving .csv file with series predictions and info')\n",
    "    \n",
    "    if os.path.exists(csv_path):\n",
    "        output_series_df.to_csv(csv_path, mode='a', header=False, index=False)\n",
    "    else:\n",
    "        output_series_df.to_csv(csv_path, mode='a', index=False)\n",
    "        \n",
    "    print('Done!')\n",
    "\n",
    "if save_files:\n",
    "    print('Saving dicom files to new folder...')\n",
    "    for series in tqdm(output_series_df['Series ID']):\n",
    "        new = df[df['Series ID'] == series]\n",
    "        series_df = output_series_df[output_series_df['Series ID'] == series]\n",
    "        predView = series_df['Predicted View'].values[0]\n",
    "\n",
    "        if save_only_desired:\n",
    "            if predView in desired_series and series_df['Confidence'].values > confidence_value:\n",
    "                for i, row in new.iterrows():\n",
    "                    fileName = row['Modality'] + '.' + row['Series ID'] + '.' + row['Instance Number'] + '.dcm'\n",
    "                    patientID = row['Patient ID'].upper()      \n",
    "                    dicom = pydicom.dcmread(row['Filename'])\n",
    "\n",
    "                    # save files to a 2-tier nested folder structure\n",
    "                    if not os.path.exists(os.path.join(dst, patientID)):\n",
    "                        os.makedirs(os.path.join(dst, patientID))\n",
    "\n",
    "                    if not os.path.exists(os.path.join(dst, patientID, predView)):\n",
    "                        os.makedirs(os.path.join(dst, patientID, predView))\n",
    "\n",
    "                    dicom.save_as(os.path.join(dst, patientID, predView, fileName))\n",
    "            else:\n",
    "                pass\n",
    "        else:\n",
    "            for i, row in new.iterrows():\n",
    "                fileName = row['Modality'] + '.' + row['Series ID'] + '.' + row['Instance Number'] + '.dcm'\n",
    "                patientID = row['Patient ID'].upper()      \n",
    "                dicom = pydicom.dcmread(row['Filename'])\n",
    "\n",
    "                # save files to a 2-tier nested folder structure\n",
    "                if not os.path.exists(os.path.join(dst, patientID)):\n",
    "                    os.makedirs(os.path.join(dst, patientID))\n",
    "\n",
    "                if not os.path.exists(os.path.join(dst, patientID, predView)):\n",
    "                    os.makedirs(os.path.join(dst, patientID, predView))\n",
    "\n",
    "                dicom.save_as(os.path.join(dst, patientID, predView, fileName))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2.0 - Directory with Multiple Patients or Series\n",
    "\n",
    "Use the following code to run the analysis over each patient and/or series in a directory individually. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS for the analysis\n",
    "src = \"../data/raw/example/\"                      # PATH to the directory containing the desired DICOM files (str)\n",
    "dst = \"../data/processed/sorted/\"                 # PATH to the output directory to save dicom files (only valid if save_dicoms = True) (str)\n",
    "\n",
    "modelname = 'ResNet50'                            # The neural network to load and used (Options: VGG19, ResNet50, or Xception)\n",
    "modelpath = '../models/'                          # PATH to the saved models (str)\n",
    "\n",
    "use_multiprocessing = False                       # Use multiprocessing to read header info (True or False)\n",
    "\n",
    "# parameters for postprocessing/saving\n",
    "csv_path = '../reports/resnet_series_predictions.csv'    # PATH to save the generated csv file (only valide if create_csv = True) (str)\n",
    "create_csv = True                                 # Save a .csv file with the series level view predictions (True or False)\n",
    "save_files = True                                 # Save dicom files to new directory (dst) (True or False)\n",
    "save_only_desired = True                          # Save only dicom files corresponding to desired views (True or False)\n",
    "confidence_value = 0.9                            # Only save series if the confidence is > a certain value (set to 0 to save all desired series, regardless of confidence) (float 0-1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(string):\n",
    "    # clean and standardize text descriptions, which makes searching files easier\n",
    "    forbidden_symbols = [\"*\", \".\", \",\", \"\\\"\", \"\\\\\", \"/\", \"|\", \"[\", \"]\", \":\", \";\", \" \"]\n",
    "    for symbol in forbidden_symbols:\n",
    "        string = string.replace(symbol, \"_\") # replace everything with an underscore\n",
    "    \n",
    "    return string.lower()  \n",
    "\n",
    "def preprocess(img):\n",
    "    # format image into tensor, standardized to 0-255\n",
    "    img = tf.cast(img, tf.float32)\n",
    "    img = tf.image.resize(tf.expand_dims(img, 2), (224,224))\n",
    "    img = tf.image.grayscale_to_rgb(img)\n",
    "    \n",
    "    # standardize\n",
    "    img = img / np.max(img)\n",
    "    img = img * 255.\n",
    "    \n",
    "    return img\n",
    "\n",
    "def predict_view(img, model, classes):\n",
    "    # make prediction on a single image\n",
    "    pred = model.predict(tf.expand_dims(img, axis=0))\n",
    "    pred = tf.argmax(pred, axis=-1)\n",
    "    pred_view = classes[int(pred)]\n",
    "    \n",
    "    return pred_view\n",
    "\n",
    "def batch_predict(batch, model, classes):\n",
    "    # make prediction on a batch of images\n",
    "    pred = model.predict(batch)\n",
    "    pred = tf.argmax(pred, axis=-1)\n",
    "    pred_view = [classes[int(x)] for x in pred]\n",
    "    \n",
    "    return pred_view\n",
    "\n",
    "def get_dicom_header(dicom_loc):\n",
    "    # read dicom file and return header information and image\n",
    "    ds = pydicom.read_file(dicom_loc, force=True)\n",
    "   \n",
    "    # get patient, study, and series information\n",
    "    patientID = clean_text(ds.get(\"PatientID\", \"NA\"))\n",
    "    studyDescription = clean_text(ds.get(\"StudyDescription\", \"NA\"))\n",
    "    seriesDescription = clean_text(ds.get(\"SeriesDescription\", \"NA\"))\n",
    "   \n",
    "    # generate new, standardized file name\n",
    "    modality = ds.get(\"Modality\",\"NA\")\n",
    "    studyInstanceUID = ds.get(\"StudyInstanceUID\",\"NA\")\n",
    "    seriesInstanceUID = ds.get(\"SeriesInstanceUID\",\"NA\")\n",
    "    seriesNumber = ds.get('SeriesNumber', 'NA')\n",
    "    instanceNumber = str(ds.get(\"InstanceNumber\",\"0\"))\n",
    "       \n",
    "    # load image data\n",
    "    array = ds.pixel_array\n",
    "    \n",
    "    return patientID, dicom_loc, modality, seriesInstanceUID, seriesNumber, instanceNumber, array, seriesDescription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_view_prediction(directory, dst, model,\n",
    "                     csv_path,\n",
    "                     create_csv,\n",
    "                     use_multiprocessing,\n",
    "                     save_files,\n",
    "                     save_only_desired,\n",
    "                     confidence_value):\n",
    "\n",
    "    # Runs the complete view prediction over the dicom files in a directory\n",
    "\n",
    "    # define possible class predictions\n",
    "    classLabels = ['SA', '4CH', '2CH RT', 'RVOT', 'OTHER', '2CH LT', 'LVOT']\n",
    "    classes = sorted(classLabels, key = str)\n",
    "\n",
    "    # define the series that are needed/desired for cardiac modeling\n",
    "    desired_series = ['4CH', 'SA', '2CH RT', '2CH LT', 'LVOT', 'RVOT']\n",
    "    \n",
    "    unsortedList = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files: \n",
    "            if \".dcm\" in file: # exclude non-dicoms, good for messy folders\n",
    "                unsortedList.append(os.path.join(root, file))\n",
    "\n",
    "    #print('%s files found.' % len(unsortedList))\n",
    "\n",
    "    if use_multiprocessing:\n",
    "        with Pool(os.cpu_count()) as p:\n",
    "            output = p.map(get_dicom_header, [dicom_loc for dicom_loc in unsortedList])\n",
    "\n",
    "    else:\n",
    "        output = []\n",
    "        for dicom_loc in tqdm(unsortedList):\n",
    "            output.append(get_dicom_header(dicom_loc))\n",
    "            \n",
    "    # generated pandas dataframe to store information from headers\n",
    "    df = pd.DataFrame(sorted(output), columns = ['Patient ID', \n",
    "                                             'Filename',\n",
    "                                             'Modality',\n",
    "                                             'Series ID', \n",
    "                                             'Series Number', \n",
    "                                             'Instance Number', \n",
    "                                             'Img', \n",
    "                                             'Series Description'])\n",
    "    \n",
    "    output_series = []\n",
    "    # make predictions and calculate confidence values\n",
    "    for series in set(df['Series ID']):\n",
    "        new = df[df['Series ID'] == series]\n",
    "\n",
    "        dataset = tf.data.Dataset.from_tensor_slices([preprocess(x) for x in new['Img'].values])\n",
    "        dataset = (dataset\n",
    "                 .batch(16)\n",
    "                 .prefetch(tf.data.experimental.AUTOTUNE))\n",
    "\n",
    "        # record info for this series\n",
    "        patient_id = new['Patient ID'].iloc[0]\n",
    "        series_num = new['Series Number'].iloc[0]\n",
    "        series_desc = new['Series Description'].iloc[0]\n",
    "        frames = len(new)\n",
    "\n",
    "        # make predictions over images\n",
    "        views = batch_predict(dataset, model, classes)\n",
    "\n",
    "        # find unique predictions and confidence for that series\n",
    "        u, count = np.unique(views, return_counts=True)\n",
    "        count_sort_ind = np.argsort(-count)\n",
    "        pred = u[count_sort_ind][0]\n",
    "        conf = np.round(np.max(count) / np.sum(count), 2)\n",
    "\n",
    "        output_series.append([patient_id.upper(), series, series_num, frames, series_desc, pred, conf])\n",
    "\n",
    "    output_series_df = pd.DataFrame(output_series, columns=['Patient ID', 'Series ID', 'Series Number', 'Frames', 'Series Description', 'Predicted View', 'Confidence'])\n",
    "    \n",
    "    if create_csv:\n",
    "        #print('Saving .csv file with series predictions and info')\n",
    "        if os.path.exists(csv_path):\n",
    "            output_series_df.to_csv(csv_path, mode='a', header=False, index=False)\n",
    "        else:\n",
    "            output_series_df.to_csv(csv_path, mode='a', index=False)\n",
    "        #print('Done!')\n",
    "\n",
    "    if save_files:\n",
    "        #print('Saving dicom files to new folder...')\n",
    "        for series in output_series_df['Series ID']:\n",
    "            new = df[df['Series ID'] == series]\n",
    "            series_df = output_series_df[output_series_df['Series ID'] == series]\n",
    "            predView = series_df['Predicted View'].values[0]\n",
    "            patientID = series_df['Patient ID'].values[0].upper()\n",
    "\n",
    "            if save_only_desired:\n",
    "                if predView in desired_series and series_df['Confidence'].values > confidence_value:\n",
    "                    for i, row in new.iterrows():\n",
    "                        fileName = row['Modality'] + '.' + row['Series ID'] + '.' + row['Instance Number'] + '.dcm'   \n",
    "                        dicom = pydicom.dcmread(row['Filename'])\n",
    "\n",
    "                        # save files to a 2-tier nested folder structure\n",
    "                        if not os.path.exists(os.path.join(dst, patientID)):\n",
    "                            os.makedirs(os.path.join(dst, patientID))\n",
    "\n",
    "                        if not os.path.exists(os.path.join(dst, patientID, predView)):\n",
    "                            os.makedirs(os.path.join(dst, patientID, predView))\n",
    "\n",
    "                        dicom.save_as(os.path.join(dst, patientID, predView, fileName))\n",
    "                else:\n",
    "                    pass\n",
    "            else:\n",
    "                for i, row in new.iterrows():\n",
    "                    fileName = row['Modality'] + '.' + row['Series ID'] + '.' + row['Instance Number'] + '.dcm'\n",
    "                    patientID = row['Patient ID'].upper()      \n",
    "                    dicom = pydicom.dcmread(row['Filename'])\n",
    "\n",
    "                    # save files to a 2-tier nested folder structure\n",
    "                    if not os.path.exists(os.path.join(dst, patientID)):\n",
    "                        os.makedirs(os.path.join(dst, patientID))\n",
    "\n",
    "                    if not os.path.exists(os.path.join(dst, patientID, predView)):\n",
    "                        os.makedirs(os.path.join(dst, patientID, predView))\n",
    "\n",
    "                    dicom.save_as(os.path.join(dst, patientID, predView, fileName))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the complete view prediction for each series, in each subdirectory using the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discovered 2 subdirectories in source folder\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:44<00:00, 22.46s/it]\n"
     ]
    }
   ],
   "source": [
    "subdirectories = next(os.walk(src))[1]\n",
    "print('Discovered {} subdirectories in source folder'.format(len(subdirectories)))\n",
    "\n",
    "# load appropriate model\n",
    "if modelname == 'ResNet50':\n",
    "        MODELPATH = os.path.join(modelpath, 'Resnet/082621_resnet.hdf5')\n",
    "        model = tf.keras.models.load_model(MODELPATH)\n",
    "        #print(model.summary())\n",
    "\n",
    "    elif modelname == 'VGG19':\n",
    "        MODELPATH = os.path.join(modelpath, 'VGG19/vgg19.hdf5')\n",
    "        model = tf.keras.models.load_model(MODELPATH)\n",
    "        #print(model.summary())\n",
    "\n",
    "    elif modelname == 'Xception':\n",
    "        MODELPATH = os.path.join(modelpath, 'XCEPTION/xception.hdf5')\n",
    "        model = tf.keras.models.load_model(MODELPATH)\n",
    "        #print(model.summary())\n",
    "\n",
    "    else:\n",
    "        print('Uknown model specified in parameters!')\n",
    "\n",
    "for subdir in tqdm(subdirectories):\n",
    "    complete_view_prediction(os.path.join(src, subdir), dst=dst, model=model,  \n",
    "                     csv_path=csv_path,\n",
    "                     create_csv=create_csv,\n",
    "                     use_multiprocessing=use_multiprocessing,\n",
    "                     save_files=save_files,\n",
    "                     save_only_desired=save_only_desired,\n",
    "                     confidence_value=confidence_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n",
      "Don't know how to reset  (), please run `%reset?` for details\n"
     ]
    }
   ],
   "source": [
    "reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ucair]",
   "language": "python",
   "name": "conda-env-ucair-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
